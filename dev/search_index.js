var documenterSearchIndex = {"docs":
[{"location":"benchmarker/#AutoTM-Artifact-Workflow-1","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"","category":"section"},{"location":"benchmarker/#PMM-1","page":"AutoTM Artifact Workflow","title":"PMM","text":"","category":"section"},{"location":"benchmarker/#GPU-1","page":"AutoTM Artifact Workflow","title":"GPU","text":"","category":"section"},{"location":"benchmarker/#Preparation-1","page":"AutoTM Artifact Workflow","title":"Preparation","text":"","category":"section"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"Navigate to the Benchmarker directory","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"cd $AUTOTM_HOME/experiments/Benchmarker","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"Run a new Julia session","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"julia --project","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"In the Julia REPL, make sure all dependencies are installed","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"julia> ]\n\n(Benchmarker) pkg> instantiate","category":"page"},{"location":"benchmarker/#Profiling-1","page":"AutoTM Artifact Workflow","title":"Profiling","text":"","category":"section"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"Because of memory overheads, the GPU experiments are split into two parts. The first part involves generating the kernel profile information. The second part is the actual running of the experiments themselves.","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"To generate the kernel profile data, perform the following sequence of commands in the Benchmarker directory","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"using Benchmarker, AutoTM\n\nBenchmarker.gpu_profile()","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"when the system finishes profiling, exit the Julia session.","category":"page"},{"location":"benchmarker/#Running-Benchmarks-1","page":"AutoTM Artifact Workflow","title":"Running Benchmarks","text":"","category":"section"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"In a new Julia session, run the benchmarks with","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"using Benchmarker, AutoTM\n\nBenchmarker.gpu_benchmarks()","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"note: Note\nThere are some default variables set for the amount of GPU DRAM and for the overhead of the ngraph/CUDA runtimes. These are set to 11 GB and 1 GB respectively for a RTX 2080Ti. With a different GPU/CUDA version, these will need to be changed. For example, if your GPU has 6 GB of memory, these values may be set usingusing Benchmarker, AutoTM\n\nBenchmarker.GPU_MAX_MEMORY[] = 6_000_000\nBenchmarker.GPU_MEMORY_OVERHEAD[] = 1_000_000Memory overhead can be queried using nvidia-smi","category":"page"},{"location":"benchmarker/#Generating-Plots-1","page":"AutoTM Artifact Workflow","title":"Generating Plots","text":"","category":"section"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"Following benchmark runs, the GPU performance plot (Figure 12) are simply generated using","category":"page"},{"location":"benchmarker/#","page":"AutoTM Artifact Workflow","title":"AutoTM Artifact Workflow","text":"Benchmarker.gpu_performance_plot()","category":"page"},{"location":"installation/#Installation-1","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"installation/#","page":"Installation","title":"Installation","text":"Clone the repository with","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"git clone --recursive https://github.com/darchr/AutoTM\nexport AUTOTM_HOME=$(pwd)/AutoTM","category":"page"},{"location":"installation/#Setup-1","page":"Installation","title":"Setup","text":"","category":"section"},{"location":"installation/#","page":"Installation","title":"Installation","text":"A simple setup needs to be performed to indicate how the project will be used. To enter the setup, run","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"cd $AUTOTM_HOME\njulia --color=yes setup.jl","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"The following selections can be made - choose which are appropriate for your system:","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"Use NVDIMMs in 1LM (requires a Cascade Lake system with Optane DC NVDIMMs)\nUse of a GPU (requires CUDA 10.1 or CUDA 10.2)\nUse Gurobi as the ILP solver (requires a Gurobi license (see below)).   If Gurobi is not selected, the open source Cbc solver will be used.   Please note that the original experiments were run with Gurobi.","category":"page"},{"location":"installation/#Building-1","page":"Installation","title":"Building","text":"","category":"section"},{"location":"installation/#","page":"Installation","title":"Installation","text":"Launch Julia from the AutoTM project","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"cd $AUTOTM_HOME/AutoTM\njulia --project","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"In the Julia REPL, press ] to switch to package (pkg) mode and run following commands:","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"julia> ]\n(AutoTM) pkg> instantiate\n(AutoTM) pkg> build -v","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"This will trigger the build process for our custom version of ngraph. Passing the -v command to build will helpfully display any errors that occur during the build process.","category":"page"},{"location":"installation/#Using-the-Gurobi-ILP-solver-(optional)-1","page":"Installation","title":"Using the Gurobi ILP solver (optional)","text":"","category":"section"},{"location":"installation/#","page":"Installation","title":"Installation","text":"The results in the AutoTM paper use Gurobi for the ILP solver. However, Gurobi requires a license to run. Free trial and academic licenses are available from the Gurobi website: https://www.gurobi.com","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"If using Gurobi, please obtain a license and install the software according the instructions on the website.","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"Then, when building the project, make sure to run","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"julia> ENV[\"GUROBI_HOME\"] = \"path/to/gurobi\"","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"in Julia before executing the build step above.","category":"page"},{"location":"installation/#","page":"Installation","title":"Installation","text":"note: Note\nUsing the Gurobi ILP solver is optional. If not selected during the setup step, an open-source solver Cbc will be used.","category":"page"},{"location":"#AutoTM-1","page":"AutoTM","title":"AutoTM","text":"","category":"section"},{"location":"#","page":"AutoTM","title":"AutoTM","text":"Documentation for the AutoTM source code and experiments/benchmarks.","category":"page"}]
}
