
# Counters Summary

The goal of this experiment is to understand more the differences in performance that we
see between AutoTM and 2LM.

```julia
using Pkg; Pkg.activate("../../AutoTM")
includet("plots.jl");
using Statistics
```

```julia
sumover = 5

function plot_bandwidth(x; sumover = sumover, kw...)
    return CounterPlots.make_plot(x, [:dram_reads, :dram_writes, :pmm_reads, :pmm_writes];
        sumover = sumover,
        plotsum = true,
        ylabel = "Bandwidth (GB/s)",
        ymax = 90,
        # Convert counter events into a bandwidth
        modifier = x -> x .* 64 ./ (1E9 * sumover),
        kw...
    )
end

function plot_tags(x; sumover = sumover, kw...)
    return CounterPlots.make_plot(data, [:tag_hit, :tag_miss_dirty, :tag_miss_clean];
        sumover = sumover,
        ylabel = "Billion Tag Checks per Second",
        modifier = x -> x ./ (1E9 * sumover),
        kw...
    )
end

function plot_queue_depth(x; sumover = sumover, kw...)
    # Make a modifier function that divides a count by the uncore clocks.
    CounterPlots.make_plot(
        data,
        [:pmm_rq, :pmm_wq],
        sumover = sumover,
        ylabel = "Mean Queue Depth",
        # Convert counter events into a bandwidth
        modifier = i -> i ./ mean.(x[:unc_clocks]) ./ sumover
    )
end
```

## DenseNet
First, we look at DenseNet - the workload where AutoTM achieves the greatest speedup over 2LM (up to 3x).

```julia
# Number of samples to aggregate
data = CounterPlots.load("large_densenet_1lm")
plot_bandwidth(data)
```

We load the data from these experimental runs. The types of counter data available are also listed for reference.

```julia
data = CounterPlots.load("large_densenet_2lm"; f = !CounterPlots.isscratchpad)
display(keys(data))
```

```julia
plot_bandwidth(data)
```

We can also plot cache tag statistics.

```julia
plot_tags(data)
```

Next, we check some of the values of the counters. Specifically, if there's a difference between read request inserts and actual read commands sent to the PMM devices. The only reason they would be different is if a significant amount of **underfill** occurs.

**Underfill** is Intel's terminology for when less than a cache line (64B) is queued for writing to DRAM/PMM. In this case, 64B must be *read* from the remote device, data is merged in the iMC, and then the merged 64B is written back to the remote device.

```julia
CounterPlots.make_plot(data, [:pmm_write_cmd, :pmm_write_insert];
    sumover = sumover,
    ylabel = "Billion Events per Second",
    # Convert counter events into a bandwidth
    modifier = x -> x ./ (1E9 * sumover)
)
```

```julia
CounterPlots.make_plot(data, [:pmm_read_cmd, :pmm_read_insert, :pmm_underfill_read];
    sumover = sumover,
    ylabel = "Billion Events per Second",
    # Convert counter events into a bandwidth
    modifier = x -> x ./ (1E9 * sumover)
)
```

We see no underfill, and essentially equal amounts of read and write traffic. Furthermore, there is no difference between write inserts and write commands. Likewise with reads.

Next, we look at how the read and write queues compare.

```julia
data = CounterPlots.load("large_densenet_1lm")
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_densenet_2lm"; f = !CounterPlots.isscratchpad)
plot_queue_depth(data)
```

### Using a Scratchpad

```julia
data = CounterPlots.load("large_densenet_2lm"; f = CounterPlots.isscratchpad)
plot_bandwidth(data)
```

Notes:
* We have higher bandwidth - especially during the forward pass
* Peaks in bandwidth are less spiky
* Towards the end of the iteration, we see more PMM reads than writes. This indicates *thrashing* in the cache. Because some tensors have been relegated to the lower memory region, we now have collisions between addresses that we did not see before when we were just striding through memory like normal.

The presence of more PMM reads should indicate that we have more *clean misses* in the DRAM cache. Lets verify that.

```julia
plot_tags(data)
```

As expected, we see many more clean misses.

## Heap Allocation Plots

Now, lets look at some mysterious heap allocation plots that, if you think hard enough, explain the phenomena that we observe above.

![](./figures/large_densenet_2lm_.pdf)
![](./figures/large_densenet_2lm__scratchpad.pdf)

# VGG 416

Large VGG is a workload where AutoTM's speedup over 2LM is more minimal. Lets do some investigation.

```julia
data = CounterPlots.load("large_vgg_1lm")
plot_bandwidth(data)
```

```julia
# Set the max_truncate threshold slightly larger for this data
data = CounterPlots.load("large_vgg_2lm"; f = !CounterPlots.isscratchpad, max_truncate = 20)
plot_bandwidth(data)
```

```julia
# Set the max_truncate threshold slightly larger for this data
data = CounterPlots.load("large_vgg_2lm"; f = CounterPlots.isscratchpad, max_truncate = 20)
plot_bandwidth(data)
```

```julia
# Set the max_truncate threshold slightly larger for this data
data = CounterPlots.load("large_vgg_2lm"; f = !CounterPlots.isscratchpad, max_truncate = 20)
plot_tags(data)
```

```julia
# Set the max_truncate threshold slightly larger for this data
data = CounterPlots.load("large_vgg_2lm"; f = CounterPlots.isscratchpad, max_truncate = 20)
plot_tags(data)
```

## Queue Depths

```julia
data = CounterPlots.load("large_vgg_1lm")
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_vgg_2lm"; f = !CounterPlots.isscratchpad, max_truncate = 20)
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_vgg_2lm"; f = CounterPlots.isscratchpad, max_truncate = 20)
plot_queue_depth(data)
```

### VGG Heap Plots

![](./figures/large_vgg_2lm_.pdf)
![](./figures/large_vgg_2lm__scratchpad.pdf)

# Resnet
For completeness, the other workloads are shown.

```julia
data = CounterPlots.load("large_resnet_1lm")
plot_bandwidth(data)
```

```julia
data = CounterPlots.load("large_resnet_2lm"; f = !CounterPlots.isscratchpad)
plot_bandwidth(data)
```

```julia
plot_tags(data)
```

```julia
data = CounterPlots.load("large_resnet_2lm"; f = CounterPlots.isscratchpad)
plot_bandwidth(data)
```

```julia
plot_tags(data)
```

```julia
data = CounterPlots.load("large_resnet_1lm")
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_resnet_2lm"; f = !CounterPlots.isscratchpad)
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_resnet_2lm"; f = CounterPlots.isscratchpad)
plot_queue_depth(data)
```

### Resnet Heap Plots

![](./figures/large_resnet_2lm_.pdf)
![](./figures/large_resnet_2lm__scratchpad.pdf)

## Inception

```julia
data = CounterPlots.load("large_inception_1lm")
plot_bandwidth(data)
```

```julia
data = CounterPlots.load("large_inception_2lm"; f = !CounterPlots.isscratchpad)
plot_bandwidth(data)
```

```julia
plot_tags(data)
```

```julia
data = CounterPlots.load("large_inception_2lm"; f = CounterPlots.isscratchpad)
plot_bandwidth(data)
```

```julia
plot_tags(data)
```

```julia
data = CounterPlots.load("large_inception_1lm")
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_inception_2lm"; f = !CounterPlots.isscratchpad)
plot_queue_depth(data)
```

```julia
data = CounterPlots.load("large_inception_2lm"; f = CounterPlots.isscratchpad)
plot_queue_depth(data)
```

Looking at the heap allocation plots, we can understand a little of why inception actually sees a slowdown.
It appears that we weren't agressive enough with our assignment of data to the "short lived" zone, as there are still writes occuring to pretty much all memory.

This, combined with the thrashing that introducing the scratchpad induces, results in a slowdown!

![](./figures/large_inception_2lm_.pdf)
![](./figures/large_inception_2lm__scratchpad.pdf)

```julia
```
